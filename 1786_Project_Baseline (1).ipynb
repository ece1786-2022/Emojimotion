{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VFJgPPh_hpy-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccd09c7c-913d-4c44-e6b1-45b1180b181b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fdf5416e150>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk import flatten\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "import torch.optim as optim\n",
        "import argparse\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "np.random.seed(43)\n",
        "torch.manual_seed(43)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data pre-processing work related to baseline model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LuVD3fyVkvcd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('cleaned_tweets.csv')\n",
        "emoji_data = pd.read_csv('emoji.csv')"
      ],
      "metadata": {
        "id": "3lOByObVmak6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8SaQoGQmvu3",
        "outputId": "a0873dda-af3c-4293-b30e-2a1d86570e3c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 222863 entries, 0 to 222862\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   index   222863 non-null  int64 \n",
            " 1   id      222863 non-null  int64 \n",
            " 2   time    222863 non-null  object\n",
            " 3   tweets  222863 non-null  object\n",
            " 4   emoji   222863 non-null  object\n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 8.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emoji_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OJcIIqMYoUoh",
        "outputId": "19c91186-74df-40b8-ece8-d4f33b1d3317"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0 symbol                    Name      Score\n",
              "0          46      üëè     CLAPPING HANDS SIGN  196063427\n",
              "1          31      üíñ         SPARKLING HEART  268002254\n",
              "2          49      üåπ                    ROSE  188924541\n",
              "3          33      ‚úÖ  WHITE HEAVY CHECK MARK  246454960\n",
              "4           8      üòî            PENSIVE FACE  610729615"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-053e5e7d-9fe8-477d-a2ff-4c7670c1f194\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>symbol</th>\n",
              "      <th>Name</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>46</td>\n",
              "      <td>üëè</td>\n",
              "      <td>CLAPPING HANDS SIGN</td>\n",
              "      <td>196063427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31</td>\n",
              "      <td>üíñ</td>\n",
              "      <td>SPARKLING HEART</td>\n",
              "      <td>268002254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>49</td>\n",
              "      <td>üåπ</td>\n",
              "      <td>ROSE</td>\n",
              "      <td>188924541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>‚úÖ</td>\n",
              "      <td>WHITE HEAVY CHECK MARK</td>\n",
              "      <td>246454960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>üòî</td>\n",
              "      <td>PENSIVE FACE</td>\n",
              "      <td>610729615</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-053e5e7d-9fe8-477d-a2ff-4c7670c1f194')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-053e5e7d-9fe8-477d-a2ff-4c7670c1f194 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-053e5e7d-9fe8-477d-a2ff-4c7670c1f194');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Formatting the input data to a desired format**"
      ],
      "metadata": {
        "id": "59b96WVosjCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_posts=[]\n",
        "target_number=[]\n",
        "target_emoji=[]\n",
        "num_emoji=2000\n",
        "#take 250 examples for now\n",
        "for e in emoji_data['symbol']:\n",
        "  tweets_posts.append(data[data.emoji==e]['tweets'][:num_emoji].tolist()) #find the first 250 (subject to change) tweets of emoji e\n",
        "  target_number.append([emoji_data[emoji_data['symbol']==e].index.values]*num_emoji) #append the index of emoji e 250 times (subject to change) to a list\n",
        "  target_emoji.append([e]*num_emoji)\n",
        "\n",
        "#they are nested list so need to flatten them\n",
        "target_number=flatten(target_number)\n",
        "target_number=[i[0] for i in target_number]\n",
        "target_emoji=flatten(target_emoji)\n",
        "tweets_posts=flatten(tweets_posts)\n",
        "\n",
        "#create a dictionary\n",
        "data2 = {'tweets':tweets_posts,\n",
        "        'emojis_num':target_number,\n",
        "         'emoji':target_emoji}"
      ],
      "metadata": {
        "id": "txYzIsUKtEyC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Validation Split**"
      ],
      "metadata": {
        "id": "uuRUh-6Nscbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "GVH6-wzR0p2Q"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert dictionary to a dataframe\n",
        "tweets_dataset = pd.DataFrame(data2)\n",
        "tweets_dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pV6C78ZnUmyd",
        "outputId": "0fb7c011-f789-4f51-fd56-53cf9aa8cdcf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              tweets  emojis_num emoji\n",
              "0  love to see it  the numbers they both pull is ...           0     üëè\n",
              "1     a story book scene.. congrats to both of you!            0     üëè\n",
              "2                  four arms  more like... \"for us\"            0     üëè\n",
              "3  here here. an amazing team of reps delivering ...           0     üëè\n",
              "4                    they should do that to all cex.           0     üëè"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57300fff-c293-413e-ac29-67a2009041d0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>emojis_num</th>\n",
              "      <th>emoji</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>love to see it  the numbers they both pull is ...</td>\n",
              "      <td>0</td>\n",
              "      <td>üëè</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a story book scene.. congrats to both of you!</td>\n",
              "      <td>0</td>\n",
              "      <td>üëè</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>four arms  more like... \"for us\"</td>\n",
              "      <td>0</td>\n",
              "      <td>üëè</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>here here. an amazing team of reps delivering ...</td>\n",
              "      <td>0</td>\n",
              "      <td>üëè</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>they should do that to all cex.</td>\n",
              "      <td>0</td>\n",
              "      <td>üëè</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57300fff-c293-413e-ac29-67a2009041d0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57300fff-c293-413e-ac29-67a2009041d0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57300fff-c293-413e-ac29-67a2009041d0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train,test0=train_test_split(tweets_dataset,test_size=0.36,random_state=1)\n",
        "valid,test=train_test_split(test0,test_size=20/36,random_state=1)\n",
        "train=train.reset_index(drop=True)\n",
        "valid=valid.reset_index(drop=True)\n",
        "test=test.reset_index(drop=True)\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "poMZ6rJBiOY2",
        "outputId": "9f1a5588-ce87-4104-d9c1-8373827400b4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              tweets  emojis_num emoji\n",
              "0                             they're so adorable!!           58     üçÉ\n",
              "1      19:33:57,travel far enough you meet yourself.          32     üíì\n",
              "2  i interviewed michael saylor and asked him abo...          37     üëá\n",
              "3  since mid-90‚Äôs around 1995 or so (i was born i...          53     üå∫\n",
              "4  congrats on winning the biggest ga ever reply ...          22    ‚úîÔ∏è"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed8d8559-e74e-41f7-9d40-d3eef9354fc6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>emojis_num</th>\n",
              "      <th>emoji</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>they're so adorable!!</td>\n",
              "      <td>58</td>\n",
              "      <td>üçÉ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>19:33:57,travel far enough you meet yourself.</td>\n",
              "      <td>32</td>\n",
              "      <td>üíì</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i interviewed michael saylor and asked him abo...</td>\n",
              "      <td>37</td>\n",
              "      <td>üëá</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>since mid-90‚Äôs around 1995 or so (i was born i...</td>\n",
              "      <td>53</td>\n",
              "      <td>üå∫</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>congrats on winning the biggest ga ever reply ...</td>\n",
              "      <td>22</td>\n",
              "      <td>‚úîÔ∏è</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed8d8559-e74e-41f7-9d40-d3eef9354fc6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed8d8559-e74e-41f7-9d40-d3eef9354fc6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed8d8559-e74e-41f7-9d40-d3eef9354fc6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert Y_data to one-hot format as required by baseline model**"
      ],
      "metadata": {
        "id": "gcT9s8VIsPPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a=train[\"tweets\"][0]\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nIso7uOHmvYi",
        "outputId": "6f4ea6b0-ff1c-4265-d458-0f1eb66e9542"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"they're so adorable!! \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b=train[\"emojis_num\"][0:3]\n",
        "c=torch.tensor(b)\n",
        "d=F.one_hot(c,num_classes=60)\n",
        "d.reshape(-1,60)\n",
        "d.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkESbuxvm2uo",
        "outputId": "83cd0ac2-1fb7-4a5e-cf89-3a316801ef11"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 60])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline Model "
      ],
      "metadata": {
        "id": "UCfheuJ-relL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TextDataset is Described in Section 3.3 of Assignment 2\n",
        "\n",
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,vocab,df):\n",
        "        # data_path = \"data\"\n",
        "        # df = pd.read_csv(os.path.join(data_path, f\"{split}.tsv\"), sep=\"\\t\")\n",
        "       \n",
        "        # X: torch.tensor (maxlen, batch_size), padded indices\n",
        "        # Y: torch.tensor of len N\n",
        "        X, Y = [], []\n",
        "        V = len(vocab.vectors)\n",
        "        for i, row in df.iterrows():\n",
        "            L = row[\"tweets\"].split()\n",
        "            # print(\"original\",row[\"tweets\"],\"L\",L)\n",
        "            X.append(torch.tensor([vocab.stoi.get(w, V-1) for w in L]))  # Use the last word in the vocab as the \"out-of-vocabulary\" token\n",
        "            temp=row[\"emojis_num\"]\n",
        "            temp=torch.tensor(temp)\n",
        "            temp=F.one_hot(temp,num_classes=60)\n",
        "            # print(\"Y\",temp)\n",
        "            Y.append(temp)\n",
        "            # Y.append(row[\"emojis_num\"])\n",
        "        self.X = X \n",
        "        self.Y = Y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx] \n"
      ],
      "metadata": {
        "id": "C3G9XOZpd2sR"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove=torchtext.vocab.GloVe(name='840B',dim=300)"
      ],
      "metadata": {
        "id": "iNFnIw8Qd7NS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=TextDataset(glove,train)\n",
        " #each dataloader is a batch\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "        dataset=train_dataset, \n",
        "        batch_size=3, \n",
        "        shuffle=False, \n",
        "        collate_fn=lambda batch: my_collate_function(batch, 'cpu'))\n"
      ],
      "metadata": {
        "id": "x1kgkhvfjsp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['tweets'][5]"
      ],
      "metadata": {
        "id": "G7Rqx-xUkdnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[5]"
      ],
      "metadata": {
        "id": "bzei6iGMkaLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter=iter(train_dataloader)\n",
        "count=0\n",
        "for a,b in train_dataloader:\n",
        "  print(a.shape)\n",
        "  count=count+1\n",
        "  print(b.shape)\n",
        "  if count==2:\n",
        "    break"
      ],
      "metadata": {
        "id": "u6CBjFQPkCfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# my_collate_function prepares batches\n",
        "# it also pads each batch with zeroes.\n",
        "def my_collate_function(batch, device):\n",
        "    # Handle the padding here\n",
        "    # batch is approximately: [dataset[i] for i in range(0, batch_size)]\n",
        "    # Since the dataset[i]'s contents is defined in the __getitem__() above, this collate function \n",
        "    # should be set correspondingly.\n",
        "    # Also: collate_function just takes one argument. To pass in additional arguments (e.g., device), \n",
        "    # we need to wrap up an anonymous function (using lambda below)\n",
        "    batch_x, batch_y = [], []\n",
        "    max_len = 0\n",
        "    for x,y in batch:\n",
        "        # print('X',x,\"Y\",y)\n",
        "        batch_y.append(y)\n",
        "        max_len = max(max_len, len(x))#longest sentence in a batch\n",
        "    for x,y in batch:\n",
        "      #if sentence not longest, set rest token as 0\n",
        "        x_p = torch.concat(\n",
        "            [x, torch.zeros(max_len - len(x))]\n",
        "        )\n",
        "        batch_x.append(x_p)\n",
        "    # print(\"batchy\",batch_y)\n",
        "    X=torch.stack(batch_x).t().int().to(device)\n",
        "    # print(\"a\",a)\n",
        "    Y=torch.stack(batch_y).t().int().to(device)\n",
        "    # print(\"b\",b)\n",
        "    return X,Y\n"
      ],
      "metadata": {
        "id": "8xVhiUGqcO-W"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Baseline(nn.Module):#Baseline model\n",
        "\n",
        "    def __init__(self, embedding_dim, vocab):\n",
        "        super(Baseline, self).__init__()\n",
        "        #100 vectors for each word \n",
        "        #embedding.shape=[embedding dim,glove.len]\n",
        "        self.embedding = nn.Embedding.from_pretrained(vocab.vectors)\n",
        "        self.fc = nn.Linear(embedding_dim, 60)\n",
        "\n",
        "    def forward(self, x, len=None):\n",
        "        #x has shape [sentence length, batch size]\n",
        "        embedded = self.embedding(x)#embedded.shape=[sentence len, batch size,embedding size]\n",
        "        # print(\"embedded\",embedded.shape)\n",
        "        average = embedded.mean(0) # average.shape=[batch size, embedding size]\n",
        "        # print(\"average\",average.shape)\n",
        "        prediction = self.fc(average)\n",
        "        # print(\"prediction\",prediction.shape)\n",
        "        # prediction=torch.nn.Softmax()(prediction)\n",
        "        prediction=F.log_softmax(prediction,dim=1)\n",
        "        # print(\"lof sofamax\",prediction.shape)\n",
        "        return prediction"
      ],
      "metadata": {
        "id": "C35fOjyoc3U0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model,dataloader,criterion):\n",
        "    total_corr=0\n",
        "    iterator=iter(dataloader)\n",
        "    temp_loss=0\n",
        "    for n, (input,labels) in enumerate(iterator):\n",
        "      prediction=model(input,input.size(dim=0))\n",
        "   \n",
        "      loss=criterion(input=prediction.float().squeeze(),target=labels.float().squeeze())\n",
        "      #Count correct examples\n",
        "      \n",
        "      prediction=torch.nn.Sigmoid()(prediction)#Êñ∞Âä†\n",
        "\n",
        "      corr = ((prediction > 0.5).squeeze().long() == labels.long())\n",
        "      total_corr=total_corr+int(corr.sum())\n",
        "      temp_loss=loss+temp_loss \n",
        "    accuracy=float(total_corr)/len(dataloader.dataset)\n",
        "    loss=(temp_loss/len(iterator))\n",
        "    #print(\"validation accuracy\",accuracy)\n",
        "    return accuracy,loss"
      ],
      "metadata": {
        "id": "vxbZ7xhpdiG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Baseline code start\n",
        "def main(args):\n",
        "    #   fix seed\n",
        "    torch.manual_seed(2)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print (\"Using device:\", device)\n",
        "\n",
        "    ### 3.3 Processing of the data ###\n",
        "    # 3.3.1\n",
        "    # The first time you run this will download a 862MB size file to .vector_cache/glove.6B.zip\n",
        "    # glove = torchtext.vocab.GloVe(name=\"6B\",dim=100) # embedding size = 100\n",
        "    glove=torchtext.vocab.GloVe(name='840B',dim=300)\n",
        "                                   \n",
        "    # 3.3.2\n",
        "\n",
        "    train_dataset=TextDataset(glove,train)\n",
        "    val_dataset = TextDataset(glove,valid)\n",
        "    test_dataset = TextDataset(glove, test)\n",
        "        \n",
        "    # 3.3.3\n",
        "    #each dataloader is a batch\n",
        "    train_dataloader = torch.utils.data.DataLoader(\n",
        "        dataset=train_dataset, \n",
        "        batch_size=args.batch_size, \n",
        "        shuffle=False, \n",
        "        collate_fn=lambda batch: my_collate_function(batch, device))\n",
        "\n",
        "    validation_dataloader = torch.utils.data.DataLoader(\n",
        "        dataset=val_dataset, \n",
        "        batch_size=args.batch_size, \n",
        "        shuffle=False, \n",
        "        collate_fn=lambda batch: my_collate_function(batch, device))\n",
        "   # print(args)\n",
        "    test_dataloader = torch.utils.data.DataLoader(\n",
        "        dataset=test_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=lambda batch: my_collate_function(batch, device))\n",
        "\n",
        "    #Constants\n",
        "    embedding_size=300\n",
        "    epochs=30\n",
        "    lr=0.001\n",
        "    criterion=torch.nn.CrossEntropyLoss()  \n",
        "\n",
        "    #training\n",
        "    model=Baseline(embedding_size,glove)\n",
        "    optimizer=torch.optim.Adam(model.parameters(), lr)\n",
        "    epoch_list=[]\n",
        "    train_loss=[]\n",
        "    accuracy_train=[]\n",
        "    accuracy_valid=[]\n",
        "    accuracy_test=[]\n",
        "    valid_loss=[]\n",
        "    test_loss=[]\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(\"epoch\",epoch)\n",
        "        train_iter=iter(train_dataloader)\n",
        "        valid_iter=iter(validation_dataloader)\n",
        "        test_iter=iter(test_dataloader)\n",
        "     \n",
        "       \n",
        "        # a,b,c=model.parameters()\n",
        "        # print(b)\n",
        "        # print(\"-----------------------------------------------------------------------------------------------\")\n",
        "        epoch_list.append(epoch+1)\n",
        "        \n",
        "\n",
        "        ##TRAINING SET\n",
        "        for n, (input,labels) in enumerate(train_iter):\n",
        "            # print(\"current epoch\",epoch)\n",
        "            labels=labels.reshape(-1,60)\n",
        "            print(\"n\",n)\n",
        "            print(\"labels\",labels.shape)\n",
        "            prediction=model(input,input.size(dim=0))\n",
        "            print(\"prediciton\",prediction.shape)\n",
        "            # print(\"prediction\",prediction)\n",
        "            # print(\"true labels\",labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss=criterion(input=prediction.float(),target=labels.float())\n",
        "            print(\"------------------------------------------\")\n",
        "            print(\"loss\",loss)\n",
        "            #backward pass and update gradient\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # #Count correct examples\n",
        "            # corr = ((prediction > 0.5).squeeze().long() == labels.long())\n",
        "            # total_corr_train=total_corr_train+int(corr.sum())\n",
        "            # temp_loss=loss+temp_loss\n",
        "                 \n",
        "        # # accuracy=float(total_corr_train)/len(train_dataset)\n",
        "        # accuracy,t_loss=evaluate(model,train_dataloader,criterion)\n",
        "        # # print(\"loss\",loss)\n",
        "        # # print(\"accuracy\",accuracy)\n",
        "        # train_loss.append(t_loss)\n",
        "        # accuracy_train.append(accuracy)\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "          print(\"-----------------------------------------------------------------------------------------------\")\n",
        "          # print('Epoch:', '%03d' % (epoch + 1), 'accuracy =', accuracy_train)\n",
        "\n",
        "     \n",
        "\n",
        "        # #validation #for 4.4\n",
        "        # # print(\"before go to valid\",temp_loss)\n",
        "        # for n, (input,labels) in enumerate(valid_iter):\n",
        "        #     # print(\"current epoch\",epoch)\n",
        "        #     prediction=model(input,input.size(dim=0)) \n",
        "        #     loss=criterion(input=prediction.float().squeeze(),target=labels.float().squeeze())\n",
        "            \n",
        "        #     \n",
        "        #     # # #Count correct examples\n",
        "        #     # corr = ((prediction > 0.5).squeeze().long() == labels.long())\n",
        "        #     # total_corr_valid=total_corr_valid+int(corr.sum())\n",
        "           \n",
        "        #     temp_loss=loss+temp_loss  \n",
        "        #     # print(\"temp loss\",temp_loss)  \n",
        "        # #print(\"validation length\",len(val_dataset)) \n",
        "        # # accuracy=float(total_corr_valid)/len(val_dataset)\n",
        "        # valid_loss.append(temp_loss/len(valid_iter))\n",
        "        \n",
        "        ###4.5 Validation loss, accuracy\n",
        "        accuracy,v_loss=evaluate(model,validation_dataloader,criterion)\n",
        "        valid_loss.append(v_loss)\n",
        "        accuracy_valid.append(accuracy)\n",
        "        #Test Loss, accuracy\n",
        "       \n",
        "        t_acc,t_loss=evaluate(model,test_dataloader,criterion)\n",
        "        test_loss.append(t_loss)\n",
        "        accuracy_test.append(t_acc)\n",
        "    \n",
        "    ####4.6\n",
        "\n",
        "    # a,b,c=model.parameters()\n",
        " \n",
        "        \n",
        "    print(\"epoch list\",epoch_list)\n",
        "\n",
        "  #  ##Train dataset\n",
        "  #   train_loss=torch.stack(train_loss)\n",
        "  #   train_loss=train_loss.detach().numpy()   \n",
        "  #   print(\"train loss\",train_loss)\n",
        "  #   print(\"train accuracy list\",accuracy_train)\n",
        "  #   ##Validation dataset\n",
        "  #   valid_loss=torch.stack(valid_loss)\n",
        "  #   valid_loss=valid_loss.detach().numpy()\n",
        "  #   print(\"valid accuracy list\",accuracy_valid)\n",
        "  #   print(\"valid loss\",valid_loss)\n",
        "  #   ##Test dataset\n",
        "  #   test_loss=torch.stack(test_loss)\n",
        "  #   test_loss=test_loss.detach().numpy()\n",
        "  #   print(\"test accuracy list\",accuracy_test)\n",
        "  #   print(\"test loss\",test_loss)\n",
        "\n",
        "\n",
        "  #   plt.plot(epoch_list,train_loss,color='magenta',label=\"training error\")\n",
        "  #   plt.plot(epoch_list,valid_loss,color='blue',label=\"validation error\")\n",
        "  #   plt.xlabel(\"Epoch\")\n",
        "  #   plt.ylabel(\"Loss\")\n",
        "  #   plt.title(\"Loss vs. Epoch\")\n",
        "  #   plt.legend(loc=\"upper right\")\n",
        "  #   plt.show()\n",
        "\n",
        "  #   plt.plot(epoch_list,accuracy_train,color='magenta',label=\"training accuracy\")\n",
        "  #   plt.plot(epoch_list,accuracy_valid,color='blue',label=\"validation accuracy\")\n",
        "  #   plt.xlabel(\"Epoch\")\n",
        "  #   plt.ylabel(\"Accuracy\")\n",
        "  #   plt.title(\"Accuracy vs. Epoch\")\n",
        "  #   plt.legend(loc=\"upper right\")\n",
        "  #   plt.show()\n",
        "\n",
        "  #   ##Plot test accuracy\n",
        "  #   plt.plot(epoch_list,accuracy_test,color='magenta',label=\"test accuracy\")\n",
        "  #   plt.xlabel(\"Epoch\")\n",
        "  #   plt.ylabel(\"Accuracy\")\n",
        "  #   plt.title(\"Accuracy vs. Epoch\")\n",
        "  #   plt.legend(loc=\"upper right\")\n",
        "  #   plt.show()\n",
        "\n",
        "  #   ##plot test loss\n",
        "  #   plt.plot(epoch_list,test_loss,color='magenta',label=\"test loss\")\n",
        "  #   plt.xlabel(\"Epoch\")\n",
        "  #   plt.ylabel(\"Error\")\n",
        "  #   plt.title(\"Error vs. Epoch\")\n",
        "  #   plt.legend(loc=\"upper right\")\n",
        "  #   plt.show()\n",
        "  #   for param_tensor in model.state_dict():\n",
        "  #     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    # Instantiate your model(s) and train them and so on \n",
        "    # We suggest parameterizing the model - k1, n1, k2, n2, and other hyperparameters\n",
        "    # so that it is easier to experiment with\n",
        "  \n",
        "\n",
        "if __name__ == '__main__':\n",
        "  parser = argparse.ArgumentParser()\n",
        "  parser.add_argument('-f')\n",
        "  parser.add_argument('--batch-size', type=int, default=10)\n",
        "  args=parser.parse_args()\n",
        "  main(args)\n"
      ],
      "metadata": {
        "id": "SPdQLx9GHe1y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "905e4817-028c-4905-99f7-d6d54499fbc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.840B.300d.zip: 2.18GB [06:51, 5.29MB/s]                            \n"
          ]
        }
      ]
    }
  ]
}