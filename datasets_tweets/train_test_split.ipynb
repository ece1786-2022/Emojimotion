{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HI1e6v2COgoJ",
        "outputId": "8ff88fe2-fb5e-4f61-ab0b-3a46c9b84cbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk import flatten\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "import torch.optim as optim\n",
        "import tensorflow as tf\n",
        "import argparse\n",
        "import os\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "# import gensim.downloader as api\n",
        "torch.cuda.empty_cache()\n",
        "np.random.seed(43)\n",
        "torch.manual_seed(43)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMMpUUc-Ov16",
        "outputId": "42bdb686-a889-4d39-fd13-52bf60dcc01d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f870d8e0350>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('cleaned_tweets.csv')\n",
        "emoji_data = pd.read_csv('emoji.csv')"
      ],
      "metadata": {
        "id": "bV0vfFvaOzc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_posts=[]\n",
        "target_number=[]\n",
        "target_emoji=[]\n",
        "num_emoji=2000\n",
        "#take 2000 examples for now\n",
        "for e in emoji_data['symbol']:\n",
        "  tweets_posts.append(data[data.emoji==e]['tweets'][:num_emoji].tolist()) #find the first 2000 (subject to change) tweets of emoji e\n",
        "  target_number.append([emoji_data[emoji_data['symbol']==e].index.values]*num_emoji) #append the index of emoji e 250 times (subject to change) to a list\n",
        "  target_emoji.append([e]*num_emoji)\n",
        "\n",
        "#they are nested list so need to flatten them\n",
        "target_number=flatten(target_number)\n",
        "target_number=[i[0] for i in target_number]\n",
        "target_emoji=flatten(target_emoji)\n",
        "tweets_posts=flatten(tweets_posts)\n",
        "\n",
        "#create a dictionary\n",
        "data2 = {'tweets':tweets_posts,\n",
        "        'emojis_num':target_number,\n",
        "         'emoji':target_emoji}"
      ],
      "metadata": {
        "id": "EB6OD4E2PCsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert dictionary to a dataframe\n",
        "tweets_dataset = pd.DataFrame(data2)\n",
        "tweets_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jmvHBYIoPG-c",
        "outputId": "f4138584-8529-4127-e8de-0c29351f429f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   tweets  emojis_num emoji\n",
              "0       love to see it the numbers they both pull is m...           0     üëè\n",
              "1              a story book scene congrats to both of you           0     üëè\n",
              "2                              four arms more like for us           0     üëè\n",
              "3       here here an amazing team of reps delivering a...           0     üëè\n",
              "4                          they should do that to all cex           0     üëè\n",
              "...                                                   ...         ...   ...\n",
              "119995  no no tonic getaway cory ranco full results an...          59    ‚ñ∂Ô∏è\n",
              "119996  this is not last dance for messi ronaldo on th...          59    ‚ñ∂Ô∏è\n",
              "119997                            with im so into you swv          59    ‚ñ∂Ô∏è\n",
              "119998  at saintcloud stormy night rue jonas mi cinfil...          59    ‚ñ∂Ô∏è\n",
              "119999                       jahsuper got by on its the w          59    ‚ñ∂Ô∏è\n",
              "\n",
              "[120000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e7f8740-93bf-4163-9216-792ced24a538\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>emojis_num</th>\n",
              "      <th>emoji</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>love to see it the numbers they both pull is m...</td>\n",
              "      <td>0</td>\n",
              "      <td>üëè</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a story book scene congrats to both of you</td>\n",
              "      <td>0</td>\n",
              "      <td>üëè</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>four arms more like for us</td>\n",
              "      <td>0</td>\n",
              "      <td>üëè</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>here here an amazing team of reps delivering a...</td>\n",
              "      <td>0</td>\n",
              "      <td>üëè</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>they should do that to all cex</td>\n",
              "      <td>0</td>\n",
              "      <td>üëè</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119995</th>\n",
              "      <td>no no tonic getaway cory ranco full results an...</td>\n",
              "      <td>59</td>\n",
              "      <td>‚ñ∂Ô∏è</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119996</th>\n",
              "      <td>this is not last dance for messi ronaldo on th...</td>\n",
              "      <td>59</td>\n",
              "      <td>‚ñ∂Ô∏è</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119997</th>\n",
              "      <td>with im so into you swv</td>\n",
              "      <td>59</td>\n",
              "      <td>‚ñ∂Ô∏è</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119998</th>\n",
              "      <td>at saintcloud stormy night rue jonas mi cinfil...</td>\n",
              "      <td>59</td>\n",
              "      <td>‚ñ∂Ô∏è</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119999</th>\n",
              "      <td>jahsuper got by on its the w</td>\n",
              "      <td>59</td>\n",
              "      <td>‚ñ∂Ô∏è</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120000 rows √ó 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e7f8740-93bf-4163-9216-792ced24a538')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e7f8740-93bf-4163-9216-792ced24a538 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e7f8740-93bf-4163-9216-792ced24a538');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train,test0=train_test_split(tweets_dataset,test_size=0.36,random_state=1,stratify=tweets_dataset['emojis_num'])\n",
        "valid,test=train_test_split(test0,test_size=20/36,random_state=1,stratify=test0['emojis_num'])\n",
        "train=train.reset_index(drop=True)\n",
        "valid=valid.reset_index(drop=True)\n",
        "test=test.reset_index(drop=True)\n",
        "# a=train[train['emojis_num']==2]\n",
        "# a.info()"
      ],
      "metadata": {
        "id": "swNqUVROPI7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TextDataset is Described in Section 3.3 of Assignment 2\n",
        "\n",
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,vocab,df):\n",
        "        # data_path = \"data\"\n",
        "        # df = pd.read_csv(os.path.join(data_path, f\"{split}.tsv\"), sep=\"\\t\")\n",
        "       \n",
        "        # X: torch.tensor (maxlen, batch_size), padded indices\n",
        "        # Y: torch.tensor of len N\n",
        "        X, Y = [], []\n",
        "        V = len(vocab.vectors)\n",
        "        for i, row in df.iterrows():\n",
        "            \n",
        "            L = row[\"tweets\"].split()\n",
        "            \n",
        "            # L = re.sub('[0-9]+', '', row['tweets']) \n",
        "            # L=re.split('[ ,.!?:$&*/\\|<>^+=-_-‚Ä¢%;„ÄÇÔΩ•Ôºå<>]',L)  \n",
        "            # L = L.split()\n",
        "            # no_extraspace = [\" \".join(i.split()) for i in no_newlinechar]\n",
        "            # L=[j for j in L if j]\n",
        "            # print(\"original\",row[\"tweets\"],\"L\",L)\n",
        "            X.append(torch.tensor([vocab.stoi.get(w, V-1) for w in L]))  # Use the last word in the vocab as the \"out-of-vocabulary\" token\n",
        "            temp=row[\"emojis_num\"]\n",
        "            temp=torch.tensor(temp)\n",
        "            temp=F.one_hot(temp,num_classes=60)\n",
        "            # print(\"Y\",temp)\n",
        "            Y.append(temp)\n",
        "            # Y.append(row[\"emojis_num\"])\n",
        "        self.X = X \n",
        "        self.Y = Y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx] \n"
      ],
      "metadata": {
        "id": "PJzVSLCtPN59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove=torchtext.vocab.GloVe(name='840B',dim=300)\n",
        "# glove=torchtext.vocab.GloVe(name='twitter.27B',dim=200)"
      ],
      "metadata": {
        "id": "OCaOg_FiPOin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# my_collate_function prepares batches\n",
        "# it also pads each batch with zeroes.\n",
        "def my_collate_function(batch, device):\n",
        "    # Handle the padding here\n",
        "    # batch is approximately: [dataset[i] for i in range(0, batch_size)]\n",
        "    # Since the dataset[i]'s contents is defined in the __getitem__() above, this collate function \n",
        "    # should be set correspondingly.\n",
        "    # Also: collate_function just takes one argument. To pass in additional arguments (e.g., device), \n",
        "    # we need to wrap up an anonymous function (using lambda below)\n",
        "    batch_x, batch_y = [], []\n",
        "    max_len = 0\n",
        "    for x,y in batch:\n",
        "        # print('X',x,\"Y\",y)\n",
        "        batch_y.append(y)\n",
        "        max_len = max(max_len, len(x))#longest sentence in a batch\n",
        "    for x,y in batch:\n",
        "      #if sentence not longest, set rest token as 0\n",
        "        x_p = torch.concat(\n",
        "            [x, torch.zeros(max_len - len(x))]\n",
        "        )\n",
        "        batch_x.append(x_p)\n",
        "    # print(\"batchy\",batch_y)\n",
        "    X=torch.stack(batch_x).t().int().to(device)\n",
        "    # print(\"a\",a)\n",
        "    Y=torch.stack(batch_y).t().int().to(device)\n",
        "    # print(\"b\",b)\n",
        "    return X,Y\n"
      ],
      "metadata": {
        "id": "cBWPWMBmPWBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Baseline(nn.Module):#Baseline model\n",
        "\n",
        "    def __init__(self, embedding_dim, vocab):\n",
        "        super(Baseline, self).__init__()\n",
        "        #100 vectors for each word \n",
        "        #embedding.shape=[embedding dim,glove.len]\n",
        "        self.embedding = nn.Embedding.from_pretrained(vocab.vectors)\n",
        "        self.fc = nn.Linear(embedding_dim, 60)#60 emojis used\n",
        "\n",
        "    def forward(self, x, len=None):\n",
        "        #x has shape [sentence length, batch size]\n",
        "        embedded = self.embedding(x)#embedded.shape=[sentence len, batch size,embedding size]\n",
        "        # print(\"embedded\",embedded.shape)\n",
        "        average = embedded.mean(0) # average.shape=[batch size, embedding size]\n",
        "        # print(\"average\",average.shape)\n",
        "        prediction = self.fc(average) #prediciton shape (bsz,60)\n",
        "        # print(\"prediction\",prediction.shape)\n",
        "        # prediction=torch.nn.Softmax()(prediction)\n",
        "        # prediction=F.log_softmax(prediction,dim=1)#prediction.shape(bsz,60)\n",
        "        # print(\"lof sofamax\",prediction.shape)\n",
        "        return prediction"
      ],
      "metadata": {
        "id": "lFRA-SPCPWkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model,dataloader,criterion):\n",
        "    total_corr=0\n",
        "    iterator=iter(dataloader)\n",
        "    temp_loss=0\n",
        "    for n, (input,labels) in enumerate(iterator):\n",
        "      labels=labels.reshape(-1,60)\n",
        "      # print(\"labels\",labels.shape)\n",
        "      prediction=model(input,input.size(dim=0))\n",
        "      # prediction=F.log_softmax(prediction,dim=1)\n",
        "      # print(\"predict\",prediction.shape)\n",
        "      loss=criterion(input=prediction.float(),target=labels.float())\n",
        "      #Count correct examples\n",
        "      k=8\n",
        "      prediction=F.softmax(prediction,dim=1)\n",
        "      _,pre=torch.topk(prediction,k,dim=1)\n",
        "      true=torch.argmax(labels,dim=1)\n",
        "      # corr=torch.count_nonzero(torch.eq(true,pre))\n",
        "      for i in range(len(true)):\n",
        "        # print(\"true[i\",true[i])\n",
        "        # print(\"predict i\",pre[i])\n",
        "        if true[i] in pre[i]:\n",
        "          # print(\"+++++++++++++++++\")\n",
        "          total_corr=total_corr+1\n",
        "          # print(\"total orr\",total_corr)\n",
        " \n",
        "      # total_corr=total_corr+int(corr.sum())\n",
        "      temp_loss=loss+temp_loss \n",
        "    accuracy=float(total_corr)/len(dataloader.dataset)\n",
        "    loss=(temp_loss/len(iterator))\n",
        "    #print(\"validation accuracy\",accuracy)\n",
        "    return accuracy,loss"
      ],
      "metadata": {
        "id": "GH_-8-xTPYcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Baseline code start\n",
        "def main(args):\n",
        "    #   fix seed\n",
        "    torch.manual_seed(2)\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print (\"Using device:\", device)\n",
        "\n",
        "    ### 3.3 Processing of the data ###\n",
        "    # 3.3.1\n",
        "    # The first time you run this will download a 862MB size file to .vector_cache/glove.6B.zip\n",
        "    # glove = torchtext.vocab.GloVe(name=\"6B\",dim=100) # embedding size = 100\n",
        "    glove=torchtext.vocab.GloVe(name='840B',dim=300)\n",
        "    # glove=torchtext.vocab.GloVe(name='twitter.27B',dim=200)\n",
        "                                   \n",
        "    # 3.3.2\n",
        "\n",
        "    train_dataset=TextDataset(glove,train)\n",
        "    val_dataset = TextDataset(glove,valid)\n",
        "    test_dataset = TextDataset(glove, test)\n",
        "        \n",
        "    # 3.3.3\n",
        "    #each dataloader is a batch\n",
        "    train_dataloader = torch.utils.data.DataLoader(\n",
        "        dataset=train_dataset, \n",
        "        batch_size=args.batch_size, \n",
        "        shuffle=False, \n",
        "        collate_fn=lambda batch: my_collate_function(batch, device))\n",
        "\n",
        "    validation_dataloader = torch.utils.data.DataLoader(\n",
        "        dataset=val_dataset, \n",
        "        batch_size=args.batch_size, \n",
        "        shuffle=False, \n",
        "        collate_fn=lambda batch: my_collate_function(batch, device))\n",
        "   # print(args)\n",
        "    test_dataloader = torch.utils.data.DataLoader(\n",
        "        dataset=test_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=False,\n",
        "        collate_fn=lambda batch: my_collate_function(batch, device))\n",
        "\n",
        "    #Constants\n",
        "    embedding_size=300\n",
        "    epochs=40\n",
        "    lr=0.0001\n",
        "    criterion=torch.nn.CrossEntropyLoss()  \n",
        "\n",
        "    #training\n",
        "    model=Baseline(embedding_size,glove).to(device)\n",
        "    optimizer=torch.optim.Adam(model.parameters(), lr)\n",
        "    epoch_list=[]\n",
        "    train_loss=[]\n",
        "    accuracy_train=[]\n",
        "    accuracy_valid=[]\n",
        "    accuracy_test=[]\n",
        "    valid_loss=[]\n",
        "    test_loss=[]\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(\"epoch\",epoch)\n",
        "        train_iter=iter(train_dataloader)\n",
        "        valid_iter=iter(validation_dataloader)\n",
        "        test_iter=iter(test_dataloader)\n",
        "     \n",
        "       \n",
        "        # a,b,c=model.parameters()\n",
        "        # print(b)\n",
        "        # print(\"-----------------------------------------------------------------------------------------------\")\n",
        "        epoch_list.append(epoch+1)\n",
        "        \n",
        "\n",
        "        ##TRAINING SET\n",
        "        for n, (input,labels) in enumerate(train_iter):\n",
        "            # print(\"current epoch\",epoch)\n",
        "            input=input.to(device)\n",
        "            labels=labels.to(device)\n",
        "            labels=labels.reshape(-1,60)\n",
        "            # print(\"n\",n)\n",
        "            # print(\"labels\",labels.shape)\n",
        "            prediction=model(input,input.size(dim=0))\n",
        "            # print(\"prediciton\",prediction.shape)\n",
        "            # print(\"prediction\",prediction)\n",
        "            # print(\"true labels\",labels)\n",
        "            optimizer.zero_grad()\n",
        "            torch.cuda.empty_cache()\n",
        "            loss=criterion(input=prediction.float(),target=labels.float())\n",
        "            # print(\"------------------------------------------\")\n",
        "            # print(\"loss\",loss)\n",
        "            #backward pass and update gradient\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "           \n",
        "            # #Count correct examples\n",
        "            # pre=torch.argmax(prediction,dim=1)\n",
        "            # true=torch.argmax(labels,dim=1)\n",
        "            # corr=torch.count_nonzero(torch.eq(true,pre))\n",
        "            # print(\"pre\",pre)\n",
        "            # print(\"true\",true)\n",
        "            # print(\"correct number\",corr)\n",
        "\n",
        "            # corr = ((prediction > 0.5).squeeze().long() == labels.long())\n",
        "            # total_corr_train=total_corr_train+int(corr.sum())\n",
        "            # temp_loss=loss+temp_loss\n",
        "                 \n",
        "        # # accuracy=float(total_corr_train)/len(train_dataset)\n",
        "        accuracy,t_loss=evaluate(model,train_dataloader,criterion)\n",
        "        print(\"loss\",loss)\n",
        "        print(\"accuracy\",accuracy)\n",
        "        train_loss.append(t_loss)\n",
        "        accuracy_train.append(accuracy)\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "          print(\"-----------------------------------------------------------------------------------------------\")\n",
        "          print('Epoch:', '%03d' % (epoch + 1), 'accuracy =', accuracy_train)\n",
        "\n",
        "     \n",
        "\n",
        "        # #validation #for 4.4\n",
        "        # # print(\"before go to valid\",temp_loss)\n",
        "        # for n, (input,labels) in enumerate(valid_iter):\n",
        "        #     # print(\"current epoch\",epoch)\n",
        "        #     prediction=model(input,input.size(dim=0)) \n",
        "        #     loss=criterion(input=prediction.float().squeeze(),target=labels.float().squeeze())\n",
        "            \n",
        "        #     \n",
        "        #     # # #Count correct examples\n",
        "        #     # corr = ((prediction > 0.5).squeeze().long() == labels.long())\n",
        "        #     # total_corr_valid=total_corr_valid+int(corr.sum())\n",
        "           \n",
        "        #     temp_loss=loss+temp_loss  \n",
        "        #     # print(\"temp loss\",temp_loss)  \n",
        "        # #print(\"validation length\",len(val_dataset)) \n",
        "        # # accuracy=float(total_corr_valid)/len(val_dataset)\n",
        "        # valid_loss.append(temp_loss/len(valid_iter))\n",
        "        \n",
        "        ###4.5 Validation loss, accuracy\n",
        "        accuracy,v_loss=evaluate(model,validation_dataloader,criterion)\n",
        "        valid_loss.append(v_loss)\n",
        "        accuracy_valid.append(accuracy)\n",
        "        #Test Loss, accuracy\n",
        "       \n",
        "        t_acc,t_loss=evaluate(model,test_dataloader,criterion)\n",
        "        test_loss.append(t_loss)\n",
        "        accuracy_test.append(t_acc)\n",
        "\n",
        "    ####4.6\n",
        "    # a,b,c=model.parameters()\n",
        "    torch.save(model.cpu().state_dict(),'/content/drive/MyDrive/Colab Notebooks/model_baseline.pt')\n",
        "    model.cuda()\n",
        "        \n",
        "    print(\"epoch list\",epoch_list)\n",
        "\n",
        "  #  ##Train dataset\n",
        "    train_loss=torch.stack(train_loss)\n",
        "    train_loss=train_loss.detach().cpu().clone().numpy()   \n",
        "    print(\"train loss\",train_loss)\n",
        "    print(\"train accuracy list\",accuracy_train)\n",
        "    ##Validation dataset\n",
        "    valid_loss=torch.stack(valid_loss)\n",
        "    valid_loss=valid_loss.detach().cpu().clone().numpy() \n",
        "    print(\"valid accuracy list\",accuracy_valid)\n",
        "    print(\"valid loss\",valid_loss)\n",
        "    ##Test dataset\n",
        "    test_loss=torch.stack(test_loss)\n",
        "    test_loss=test_loss.detach().cpu().clone().numpy() \n",
        "    print(\"test accuracy list\",accuracy_test)\n",
        "    print(\"test loss\",test_loss)\n",
        "\n",
        "\n",
        "    plt.plot(epoch_list,train_loss,color='magenta',label=\"training error\")\n",
        "    plt.plot(epoch_list,valid_loss,color='blue',label=\"validation error\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Loss vs. Epoch\")\n",
        "    plt.legend(loc=\"upper right\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(epoch_list,accuracy_train,color='magenta',label=\"training accuracy\")\n",
        "    plt.plot(epoch_list,accuracy_valid,color='blue',label=\"validation accuracy\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Accuracy vs. Epoch\")\n",
        "    plt.legend(loc=\"upper right\")\n",
        "    plt.show()\n",
        "    \n",
        "    ##Plot test accuracy\n",
        "    plt.plot(epoch_list,accuracy_test,color='magenta',label=\"test accuracy\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Accuracy vs. Epoch\")\n",
        "    plt.legend(loc=\"upper right\")\n",
        "    plt.show()\n",
        "\n",
        "    ##plot test loss\n",
        "    plt.plot(epoch_list,test_loss,color='magenta',label=\"test loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Error\")\n",
        "    plt.title(\"Error vs. Epoch\")\n",
        "    plt.legend(loc=\"upper right\")\n",
        "    plt.show()\n",
        "    return model\n",
        "  #   for param_tensor in model.state_dict():\n",
        "  #     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
      ],
      "metadata": {
        "id": "WaamCosHPaic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  parser = argparse.ArgumentParser()\n",
        "  parser.add_argument('-f')\n",
        "  parser.add_argument('--batch-size', type=int, default=5)\n",
        "  args=parser.parse_args()\n",
        "  main(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ForDjF2FQDS-",
        "outputId": "4dbf47e2-5389-4221-b2e9-9c46374f6e4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "epoch 0\n",
            "loss tensor(4.0985, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "accuracy 0.115078125\n",
            "epoch 1\n",
            "loss tensor(4.0908, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "accuracy 0.12721354166666668\n",
            "epoch 2\n",
            "loss tensor(4.0830, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "accuracy 0.13782552083333333\n",
            "epoch 3\n",
            "loss tensor(4.0751, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "accuracy 0.1466796875\n",
            "epoch 4\n",
            "loss tensor(4.0671, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "accuracy 0.15348958333333335\n",
            "epoch 5\n",
            "loss tensor(4.0591, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "accuracy 0.16016927083333332\n",
            "epoch 6\n",
            "loss tensor(4.0512, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "accuracy 0.16416666666666666\n",
            "epoch 7\n",
            "loss tensor(4.0434, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "accuracy 0.1679296875\n",
            "epoch 8\n",
            "loss tensor(4.0357, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "accuracy 0.1715234375\n",
            "epoch 9\n",
            "loss tensor(4.0283, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "accuracy 0.17484375\n",
            "-----------------------------------------------------------------------------------------------\n",
            "Epoch: 010 accuracy = [0.115078125, 0.12721354166666668, 0.13782552083333333, 0.1466796875, 0.15348958333333335, 0.16016927083333332, 0.16416666666666666, 0.1679296875, 0.1715234375, 0.17484375]\n",
            "epoch 10\n",
            "loss tensor(4.0210, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "accuracy 0.1776953125\n",
            "epoch 11\n",
            "loss tensor(4.0140, device='cuda:0', grad_fn=<DivBackward1>)\n",
            "accuracy 0.18032552083333334\n",
            "epoch 12\n"
          ]
        }
      ]
    }
  ]
}